{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "patent-camcorder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 99;\n",
       "                var nbb_unformatted_code = \"# from pydantic import BaseSettings\\nfrom functools import lru_cache\\nfrom typing import List, Mapping\\n\\nimport dill\\nfrom datetime import datetime, timedelta\\nimport random\\n\\nimport pandas as pd\\nimport numpy as np\\n\\nimport math\\nimport seaborn as sns\\n\\n\\nfrom scipy.stats import multivariate_normal, multinomial\\nfrom typing import Tuple\\nfrom numpy.random import random_sample, randn\\nfrom sklearn.datasets import make_spd_matrix\\nfrom matplotlib import pyplot as plt\\nfrom sklearn.datasets import make_blobs\\n\\nfrom collections import namedtuple\\nfrom time import process_time\\n\\n# Third Party\\nfrom sklearn.compose import make_column_transformer\\nfrom sklearn.metrics import confusion_matrix\\nfrom sklearn.pipeline import Pipeline, make_pipeline\\nfrom sklearn.preprocessing import FunctionTransformer\\nfrom scipy import stats\\n\\nimport warnings\\nfrom collections import OrderedDict\\nimport os\\n\\nfrom datetime import datetime as dt\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Named tuple to help structure results\\nPipelinesTuple = namedtuple(\\\"PipelinesTuple\\\", [\\\"approved\\\", \\\"rejected\\\"])\\n\\n\\nfrom kuberspatiotemporal import CompoundModel, Feature, SpatialModel, KuberModel\\nfrom kuberspatiotemporal.tools.tools import check_spd, check_singular, repr_list_ndarray\\n\\nfrom kuberspatiotemporal.tools.data import (\\n    FeatureSelector,\\n    get_column_transformer,\\n    split_anomaly_dataset,\\n)\\n\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"# from pydantic import BaseSettings\\nfrom functools import lru_cache\\nfrom typing import List, Mapping\\n\\nimport dill\\nfrom datetime import datetime, timedelta\\nimport random\\n\\nimport pandas as pd\\nimport numpy as np\\n\\nimport math\\nimport seaborn as sns\\n\\n\\nfrom scipy.stats import multivariate_normal, multinomial\\nfrom typing import Tuple\\nfrom numpy.random import random_sample, randn\\nfrom sklearn.datasets import make_spd_matrix\\nfrom matplotlib import pyplot as plt\\nfrom sklearn.datasets import make_blobs\\n\\nfrom collections import namedtuple\\nfrom time import process_time\\n\\n# Third Party\\nfrom sklearn.compose import make_column_transformer\\nfrom sklearn.metrics import confusion_matrix\\nfrom sklearn.pipeline import Pipeline, make_pipeline\\nfrom sklearn.preprocessing import FunctionTransformer\\nfrom scipy import stats\\n\\nimport warnings\\nfrom collections import OrderedDict\\nimport os\\n\\nfrom datetime import datetime as dt\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Named tuple to help structure results\\nPipelinesTuple = namedtuple(\\\"PipelinesTuple\\\", [\\\"approved\\\", \\\"rejected\\\"])\\n\\n\\nfrom kuberspatiotemporal import CompoundModel, Feature, SpatialModel, KuberModel\\nfrom kuberspatiotemporal.tools.tools import check_spd, check_singular, repr_list_ndarray\\n\\nfrom kuberspatiotemporal.tools.data import (\\n    FeatureSelector,\\n    get_column_transformer,\\n    split_anomaly_dataset,\\n)\\n\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from pydantic import BaseSettings\n",
    "from functools import lru_cache\n",
    "from typing import List, Mapping\n",
    "\n",
    "import dill\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from scipy.stats import multivariate_normal, multinomial\n",
    "from typing import Tuple\n",
    "from numpy.random import random_sample, randn\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from collections import namedtuple\n",
    "from time import process_time\n",
    "\n",
    "# Third Party\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "\n",
    "from datetime import datetime as dt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Named tuple to help structure results\n",
    "PipelinesTuple = namedtuple(\"PipelinesTuple\", [\"approved\", \"rejected\"])\n",
    "\n",
    "\n",
    "from kuberspatiotemporal import CompoundModel, Feature, SpatialModel, KuberModel\n",
    "from kuberspatiotemporal.tools.tools import check_spd, check_singular, repr_list_ndarray\n",
    "\n",
    "from kuberspatiotemporal.tools.data import (\n",
    "    FeatureSelector,\n",
    "    get_column_transformer,\n",
    "    split_anomaly_dataset,\n",
    ")\n",
    "\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "mature-therapy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"import logging\\n\\nlogging.getLogger(\\\"imported_module\\\").setLevel(logging.WARNING)\";\n",
       "                var nbb_formatted_code = \"import logging\\n\\nlogging.getLogger(\\\"imported_module\\\").setLevel(logging.WARNING)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.getLogger(\"imported_module\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "final-recording",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>application_uid</th>\n",
       "      <th>auth_status</th>\n",
       "      <th>fingerprinttimezone</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-09 00:20:44+00:00</td>\n",
       "      <td>34ddbe55360c183dcfdc6e913a23c398cc1fa77452d1b4...</td>\n",
       "      <td>expired</td>\n",
       "      <td>{value=null}</td>\n",
       "      <td>day1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-09 00:20:18+00:00</td>\n",
       "      <td>34ddbe55360c183dcfdc6e913a23c398cc1fa77452d1b4...</td>\n",
       "      <td>approved</td>\n",
       "      <td>{value=null}</td>\n",
       "      <td>day1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-09 00:17:49+00:00</td>\n",
       "      <td>34ddbe55360c183dcfdc6e913a23c398cc1fa77452d1b4...</td>\n",
       "      <td>approved</td>\n",
       "      <td>{value=null}</td>\n",
       "      <td>day1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-09 00:17:00+00:00</td>\n",
       "      <td>34ddbe55360c183dcfdc6e913a23c398cc1fa77452d1b4...</td>\n",
       "      <td>approved</td>\n",
       "      <td>{value=null}</td>\n",
       "      <td>day1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-09 00:16:30+00:00</td>\n",
       "      <td>34ddbe55360c183dcfdc6e913a23c398cc1fa77452d1b4...</td>\n",
       "      <td>approved</td>\n",
       "      <td>{value=null}</td>\n",
       "      <td>day1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp  \\\n",
       "0 2021-03-09 00:20:44+00:00   \n",
       "1 2021-03-09 00:20:18+00:00   \n",
       "2 2021-03-09 00:17:49+00:00   \n",
       "3 2021-03-09 00:17:00+00:00   \n",
       "4 2021-03-09 00:16:30+00:00   \n",
       "\n",
       "                                     application_uid auth_status  \\\n",
       "0  34ddbe55360c183dcfdc6e913a23c398cc1fa77452d1b4...     expired   \n",
       "1  34ddbe55360c183dcfdc6e913a23c398cc1fa77452d1b4...    approved   \n",
       "2  34ddbe55360c183dcfdc6e913a23c398cc1fa77452d1b4...    approved   \n",
       "3  34ddbe55360c183dcfdc6e913a23c398cc1fa77452d1b4...    approved   \n",
       "4  34ddbe55360c183dcfdc6e913a23c398cc1fa77452d1b4...    approved   \n",
       "\n",
       "  fingerprinttimezone weekday  \n",
       "0        {value=null}    day1  \n",
       "1        {value=null}    day1  \n",
       "2        {value=null}    day1  \n",
       "3        {value=null}    day1  \n",
       "4        {value=null}    day1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"data = pd.read_csv(\\n    \\\"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\\\",\\n    usecols=[\\\"timestamp\\\", \\\"application_uid\\\", \\\"auth_status\\\", \\\"fingerprinttimezone\\\"],\\n)\\n\\ndata[\\\"timestamp\\\"] = data[\\\"timestamp\\\"].apply(lambda x: dt.fromtimestamp(x))\\ndata[\\\"timestamp\\\"] = data.timestamp.dt.tz_localize(\\\"UTC\\\")\\ndata[\\\"weekday\\\"] = data[\\\"timestamp\\\"].apply(lambda x: \\\"day\\\" + str(x.weekday()))\\ndf = data.copy()\\n\\ndata.head()\";\n",
       "                var nbb_formatted_code = \"data = pd.read_csv(\\n    \\\"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\\\",\\n    usecols=[\\\"timestamp\\\", \\\"application_uid\\\", \\\"auth_status\\\", \\\"fingerprinttimezone\\\"],\\n)\\n\\ndata[\\\"timestamp\\\"] = data[\\\"timestamp\\\"].apply(lambda x: dt.fromtimestamp(x))\\ndata[\\\"timestamp\\\"] = data.timestamp.dt.tz_localize(\\\"UTC\\\")\\ndata[\\\"weekday\\\"] = data[\\\"timestamp\\\"].apply(lambda x: \\\"day\\\" + str(x.weekday()))\\ndf = data.copy()\\n\\ndata.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    \"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\",\n",
    "    usecols=[\"timestamp\", \"application_uid\", \"auth_status\", \"fingerprinttimezone\"],\n",
    ")\n",
    "\n",
    "data[\"timestamp\"] = data[\"timestamp\"].apply(lambda x: dt.fromtimestamp(x))\n",
    "data[\"timestamp\"] = data.timestamp.dt.tz_localize(\"UTC\")\n",
    "data[\"weekday\"] = data[\"timestamp\"].apply(lambda x: \"day\" + str(x.weekday()))\n",
    "#df = data.copy()\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "committed-creativity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 236;\n",
       "                var nbb_unformatted_code = \"def test_feature_determination(data : pd.DataFrame , column_str : str, noise_probability = 0.005, **kwargs):\\n    fs = FeatureSelector(data[column_str])\\n    fs.select()\\n    X_train = data[column_str].sample(3000)\\n    X_train = X_train[\\n        np.concatenate(\\n            (fs.categorical_features, fs.numerical_features , fs.time_feature)\\n        )\\n    ]\\n    n_components = 100\\n\\n    # get transformers\\n    column_transformer, index = get_column_transformer(fs)\\n\\n    # features model\\n    features_cpd_model = []\\n    n_dim = len(fs.time_feature) + len(fs.numerical_features) + len(fs.categorical_features)\\n\\n    idx_spatial = np.concatenate((index[\\\"numerical\\\"], index[\\\"numerical_time\\\"])).astype('int')\\n    idx_kuber = np.concatenate((index[\\\"categorical\\\"], index[\\\"categorical_time\\\"])).astype('int')\\n\\n    if len(idx_spatial) > 0:\\n\\n        spatial_transformed = column_transformer.fit_transform(X_train)[:, idx_spatial]\\n\\n        limits = np.array(\\n            [\\n                np.min(spatial_transformed, axis=0),\\n                np.max(spatial_transformed, axis=0),\\n            ]\\n        )\\n\\n        features_cpd_model.append(\\n            Feature(\\n                SpatialModel(\\n                    n_dim=len(idx_spatial),\\n                    n_components= n_components,\\n                    min_eigval=1e-10,\\n                    limits=limits,\\n                    covar_factor=np.array([np.cov(spatial_transformed[:, i], spatial_transformed[:, i])[\\n                                        0][0] for i in range(spatial_transformed.shape[1])]),\\n                    **kwargs\\n                    \\n                ),\\n                idx_spatial,\\n            )\\n        )\\n\\n    # I create a KuberModel for each category\\n    spatial_transformed = column_transformer.fit_transform(X_train)[:, idx_kuber]\\n\\n    for idx_cat, name in zip(idx_kuber, fs.categorical_features):\\n        features_cpd_model.append(\\n            Feature(\\n                KuberModel(n_components= n_components,n_symbols=len(fs.get_categories(name))),\\n                [idx_cat],\\n            )\\n        )\\n    #print(len(features_cpd_model))\\n\\n    # Then, a CompoundModel is created: it includes both Spatial and Kuber models\\n    #print(index.values())\\n    kst = CompoundModel(\\n        n_dim=np.sum([len(x) for x in index.values()]),\\n        n_components= n_components, \\n        n_iterations=200,\\n        scaling_parameter=1.1,\\n        nonparametric=True,\\n        online_learning=False,\\n        loa=True,\\n        features=features_cpd_model,\\n        noise_probability = noise_probability\\n\\n    )\\n    print('fs.categorical_features', fs.categorical_features) #================================\\n    print('fs.numerical_features',fs.numerical_features) #=====================================\\n    print('fs.time_feature', fs.time_feature) #================================================\\n\\n    pipeline_approved = make_pipeline(column_transformer, kst)\\n    pipeline_approved.fit(X_train)\\n\\n\\n    X = pipeline_approved[\\\"columntransformer\\\"].transform(X_train)\\n    return (kst, pipeline_approved)\";\n",
       "                var nbb_formatted_code = \"def test_feature_determination(\\n    data: pd.DataFrame, column_str: str, noise_probability=0.005, **kwargs\\n):\\n    fs = FeatureSelector(data[column_str])\\n    fs.select()\\n    X_train = data[column_str].sample(3000)\\n    X_train = X_train[\\n        np.concatenate(\\n            (fs.categorical_features, fs.numerical_features, fs.time_feature)\\n        )\\n    ]\\n    n_components = 100\\n\\n    # get transformers\\n    column_transformer, index = get_column_transformer(fs)\\n\\n    # features model\\n    features_cpd_model = []\\n    n_dim = (\\n        len(fs.time_feature) + len(fs.numerical_features) + len(fs.categorical_features)\\n    )\\n\\n    idx_spatial = np.concatenate((index[\\\"numerical\\\"], index[\\\"numerical_time\\\"])).astype(\\n        \\\"int\\\"\\n    )\\n    idx_kuber = np.concatenate(\\n        (index[\\\"categorical\\\"], index[\\\"categorical_time\\\"])\\n    ).astype(\\\"int\\\")\\n\\n    if len(idx_spatial) > 0:\\n\\n        spatial_transformed = column_transformer.fit_transform(X_train)[:, idx_spatial]\\n\\n        limits = np.array(\\n            [np.min(spatial_transformed, axis=0), np.max(spatial_transformed, axis=0),]\\n        )\\n\\n        features_cpd_model.append(\\n            Feature(\\n                SpatialModel(\\n                    n_dim=len(idx_spatial),\\n                    n_components=n_components,\\n                    min_eigval=1e-10,\\n                    limits=limits,\\n                    covar_factor=np.array(\\n                        [\\n                            np.cov(\\n                                spatial_transformed[:, i], spatial_transformed[:, i]\\n                            )[0][0]\\n                            for i in range(spatial_transformed.shape[1])\\n                        ]\\n                    ),\\n                    **kwargs\\n                ),\\n                idx_spatial,\\n            )\\n        )\\n\\n    # I create a KuberModel for each category\\n    spatial_transformed = column_transformer.fit_transform(X_train)[:, idx_kuber]\\n\\n    for idx_cat, name in zip(idx_kuber, fs.categorical_features):\\n        features_cpd_model.append(\\n            Feature(\\n                KuberModel(\\n                    n_components=n_components, n_symbols=len(fs.get_categories(name))\\n                ),\\n                [idx_cat],\\n            )\\n        )\\n    # print(len(features_cpd_model))\\n\\n    # Then, a CompoundModel is created: it includes both Spatial and Kuber models\\n    # print(index.values())\\n    kst = CompoundModel(\\n        n_dim=np.sum([len(x) for x in index.values()]),\\n        n_components=n_components,\\n        n_iterations=200,\\n        scaling_parameter=1.1,\\n        nonparametric=True,\\n        online_learning=False,\\n        loa=True,\\n        features=features_cpd_model,\\n        noise_probability=noise_probability,\\n    )\\n    print(\\n        \\\"fs.categorical_features\\\", fs.categorical_features\\n    )  # ================================\\n    print(\\n        \\\"fs.numerical_features\\\", fs.numerical_features\\n    )  # =====================================\\n    print(\\n        \\\"fs.time_feature\\\", fs.time_feature\\n    )  # ================================================\\n\\n    pipeline_approved = make_pipeline(column_transformer, kst)\\n    pipeline_approved.fit(X_train)\\n\\n    X = pipeline_approved[\\\"columntransformer\\\"].transform(X_train)\\n    return (kst, pipeline_approved)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_feature_determination(data : pd.DataFrame , column_str : str, noise_probability = 0.005, **kwargs):\n",
    "    fs = FeatureSelector(data[column_str])\n",
    "    fs.select()\n",
    "    X_train = data[column_str].sample(3000)\n",
    "    X_train = X_train[\n",
    "        np.concatenate(\n",
    "            (fs.categorical_features, fs.numerical_features , fs.time_feature)\n",
    "        )\n",
    "    ]\n",
    "    n_components = 100\n",
    "\n",
    "    # get transformers\n",
    "    column_transformer, index = get_column_transformer(fs)\n",
    "\n",
    "    # features model\n",
    "    features_cpd_model = []\n",
    "    n_dim = len(fs.time_feature) + len(fs.numerical_features) + len(fs.categorical_features)\n",
    "\n",
    "    idx_spatial = np.concatenate((index[\"numerical\"], index[\"numerical_time\"])).astype('int')\n",
    "    idx_kuber = np.concatenate((index[\"categorical\"], index[\"categorical_time\"])).astype('int')\n",
    "\n",
    "    if len(idx_spatial) > 0:\n",
    "\n",
    "        spatial_transformed = column_transformer.fit_transform(X_train)[:, idx_spatial]\n",
    "\n",
    "        limits = np.array(\n",
    "            [\n",
    "                np.min(spatial_transformed, axis=0),\n",
    "                np.max(spatial_transformed, axis=0),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        features_cpd_model.append(\n",
    "            Feature(\n",
    "                SpatialModel(\n",
    "                    n_dim=len(idx_spatial),\n",
    "                    n_components= n_components,\n",
    "                    min_eigval=1e-10,\n",
    "                    limits=limits,\n",
    "                    covar_factor=np.array([np.cov(spatial_transformed[:, i], spatial_transformed[:, i])[\n",
    "                                        0][0] for i in range(spatial_transformed.shape[1])]),\n",
    "                    **kwargs\n",
    "                    \n",
    "                ),\n",
    "                idx_spatial,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # I create a KuberModel for each category\n",
    "    spatial_transformed = column_transformer.fit_transform(X_train)[:, idx_kuber]\n",
    "\n",
    "    for idx_cat, name in zip(idx_kuber, fs.categorical_features):\n",
    "        features_cpd_model.append(\n",
    "            Feature(\n",
    "                KuberModel(n_components= n_components,n_symbols=len(fs.get_categories(name))),\n",
    "                [idx_cat],\n",
    "            )\n",
    "        )\n",
    "    #print(len(features_cpd_model))\n",
    "\n",
    "    # Then, a CompoundModel is created: it includes both Spatial and Kuber models\n",
    "    #print(index.values())\n",
    "    kst = CompoundModel(\n",
    "        n_dim=np.sum([len(x) for x in index.values()]),\n",
    "        n_components= n_components, \n",
    "        n_iterations=200,\n",
    "        scaling_parameter=1.1,\n",
    "        nonparametric=True,\n",
    "        online_learning=False,\n",
    "        loa=True,\n",
    "        features=features_cpd_model,\n",
    "        noise_probability = noise_probability\n",
    "\n",
    "    )\n",
    "    print('fs.categorical_features', fs.categorical_features) #================================\n",
    "    print('fs.numerical_features',fs.numerical_features) #=====================================\n",
    "    print('fs.time_feature', fs.time_feature) #================================================\n",
    "\n",
    "    pipeline_approved = make_pipeline(column_transformer, kst)\n",
    "    pipeline_approved.fit(X_train)\n",
    "\n",
    "\n",
    "    X = pipeline_approved[\"columntransformer\"].transform(X_train)\n",
    "    return (kst, pipeline_approved)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-zealand",
   "metadata": {},
   "source": [
    "## Using 1-D UTC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "modified-accommodation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fs.categorical_features []\n",
      "fs.numerical_features []\n",
      "fs.time_feature ['timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed columns:  \n",
      " [[0.33833333]\n",
      " [0.29694444]\n",
      " [0.28333333]\n",
      " [0.275     ]] \n",
      " Sample Scores:  \n",
      " [0.78605056 0.7751326  0.77127357 0.76884274]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"data = pd.read_csv(\\n    \\\"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\\\",\\n    usecols=[\\\"timestamp\\\", \\\"application_uid\\\", \\\"auth_status\\\", \\\"fingerprinttimezone\\\"],\\n)\\n\\ndata[\\\"timestamp\\\"] = data[\\\"timestamp\\\"].apply(lambda x: dt.fromtimestamp(x))\\ndata[\\\"timestamp\\\"] = data.timestamp.dt.tz_localize(\\\"UTC\\\")\\n\\ncolumn_str = [\\\"timestamp\\\"]\\n\\nkst, pipeline_approved = test_feature_determination(data, column_str)\\n\\nX = pipeline_approved[\\\"columntransformer\\\"].transform(data[column_str])\\n\\nprint(\\n    \\\"Transformed columns: \\\",\\n    \\\"\\\\n\\\",\\n    X[1:5, :],\\n    \\\"\\\\n\\\",\\n    \\\"Sample Scores: \\\",\\n    \\\"\\\\n\\\",\\n    kst.score_samples(X[1:5, :]),\\n)\";\n",
       "                var nbb_formatted_code = \"data = pd.read_csv(\\n    \\\"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\\\",\\n    usecols=[\\\"timestamp\\\", \\\"application_uid\\\", \\\"auth_status\\\", \\\"fingerprinttimezone\\\"],\\n)\\n\\ndata[\\\"timestamp\\\"] = data[\\\"timestamp\\\"].apply(lambda x: dt.fromtimestamp(x))\\ndata[\\\"timestamp\\\"] = data.timestamp.dt.tz_localize(\\\"UTC\\\")\\n\\ncolumn_str = [\\\"timestamp\\\"]\\n\\nkst, pipeline_approved = test_feature_determination(data, column_str)\\n\\nX = pipeline_approved[\\\"columntransformer\\\"].transform(data[column_str])\\n\\nprint(\\n    \\\"Transformed columns: \\\",\\n    \\\"\\\\n\\\",\\n    X[1:5, :],\\n    \\\"\\\\n\\\",\\n    \\\"Sample Scores: \\\",\\n    \\\"\\\\n\\\",\\n    kst.score_samples(X[1:5, :]),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    \"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\",\n",
    "    usecols=[\"timestamp\", \"application_uid\", \"auth_status\", \"fingerprinttimezone\"],\n",
    ")\n",
    "\n",
    "data[\"timestamp\"] = data[\"timestamp\"].apply(lambda x: dt.fromtimestamp(x))\n",
    "data[\"timestamp\"] = data.timestamp.dt.tz_localize(\"UTC\")\n",
    "\n",
    "column_str = [\"timestamp\"]\n",
    "\n",
    "kst, pipeline_approved = test_feature_determination(data, column_str)\n",
    "\n",
    "X = pipeline_approved[\"columntransformer\"].transform(data[column_str])\n",
    "\n",
    "print(\n",
    "    \"Transformed columns: \",\n",
    "    \"\\n\",\n",
    "    X[1:5, :],\n",
    "    \"\\n\",\n",
    "    \"Sample Scores: \",\n",
    "    \"\\n\",\n",
    "    kst.score_samples(X[1:5, :]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-drink",
   "metadata": {},
   "source": [
    "## Using 1-D non-UTC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aging-appreciation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fs.categorical_features []\n",
      "fs.numerical_features []\n",
      "fs.time_feature ['timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed columns:  \n",
      " [[0.33833333]\n",
      " [0.29694444]\n",
      " [0.28333333]\n",
      " [0.275     ]] \n",
      " Sample Scores:  \n",
      " [0.63818322 0.63270264 0.63087046 0.62974144]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"data = pd.read_csv(\\n    \\\"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\\\",\\n    usecols=[\\\"timestamp\\\", \\\"application_uid\\\", \\\"auth_status\\\", \\\"fingerprinttimezone\\\"],\\n)\\n\\ndata[\\\"timestamp\\\"] = data[\\\"timestamp\\\"].apply(lambda x: dt.fromtimestamp(x))\\n\\ncolumn_str = [\\\"timestamp\\\"]\\n\\nkst, pipeline_approved = test_feature_determination(data, column_str)\\n\\nX = pipeline_approved[\\\"columntransformer\\\"].transform(data[column_str])\\n\\nprint(\\n    \\\"Transformed columns: \\\",\\n    \\\"\\\\n\\\",\\n    X[1:5, :],\\n    \\\"\\\\n\\\",\\n    \\\"Sample Scores: \\\",\\n    \\\"\\\\n\\\",\\n    kst.score_samples(X[1:5, :]),\\n)\";\n",
       "                var nbb_formatted_code = \"data = pd.read_csv(\\n    \\\"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\\\",\\n    usecols=[\\\"timestamp\\\", \\\"application_uid\\\", \\\"auth_status\\\", \\\"fingerprinttimezone\\\"],\\n)\\n\\ndata[\\\"timestamp\\\"] = data[\\\"timestamp\\\"].apply(lambda x: dt.fromtimestamp(x))\\n\\ncolumn_str = [\\\"timestamp\\\"]\\n\\nkst, pipeline_approved = test_feature_determination(data, column_str)\\n\\nX = pipeline_approved[\\\"columntransformer\\\"].transform(data[column_str])\\n\\nprint(\\n    \\\"Transformed columns: \\\",\\n    \\\"\\\\n\\\",\\n    X[1:5, :],\\n    \\\"\\\\n\\\",\\n    \\\"Sample Scores: \\\",\\n    \\\"\\\\n\\\",\\n    kst.score_samples(X[1:5, :]),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    \"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\",\n",
    "    usecols=[\"timestamp\", \"application_uid\", \"auth_status\", \"fingerprinttimezone\"],\n",
    ")\n",
    "\n",
    "data[\"timestamp\"] = data[\"timestamp\"].apply(lambda x: dt.fromtimestamp(x))\n",
    "\n",
    "column_str = [\"timestamp\"]\n",
    "\n",
    "kst, pipeline_approved = test_feature_determination(data, column_str)\n",
    "\n",
    "X = pipeline_approved[\"columntransformer\"].transform(data[column_str])\n",
    "\n",
    "print(\n",
    "    \"Transformed columns: \",\n",
    "    \"\\n\",\n",
    "    X[1:5, :],\n",
    "    \"\\n\",\n",
    "    \"Sample Scores: \",\n",
    "    \"\\n\",\n",
    "    kst.score_samples(X[1:5, :]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-objective",
   "metadata": {},
   "source": [
    "## Using timestamp + weekday (Current KT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "contemporary-visibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fs.categorical_features ['weekday']\n",
      "fs.numerical_features []\n",
      "fs.time_feature ['timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 3000)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed columns:  \n",
      " [[0.33833333 1.        ]\n",
      " [0.29694444 1.        ]\n",
      " [0.28333333 1.        ]\n",
      " [0.275      1.        ]] \n",
      " Sample Scores:  \n",
      " [0.54621568 0.53471571 0.530748   0.52827346]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 244;\n",
       "                var nbb_unformatted_code = \"data = pd.read_csv(\\n    \\\"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\\\",\\n    usecols=[\\\"timestamp\\\", \\\"application_uid\\\", \\\"auth_status\\\", \\\"fingerprinttimezone\\\"],\\n)\\n\\ndata[\\\"timestamp\\\"] = data[\\\"timestamp\\\"].apply(lambda x: dt.fromtimestamp(x))\\ndata[\\\"weekday\\\"] = data[\\\"timestamp\\\"].apply(lambda x: \\\"day\\\" + str(x.weekday()))\\n\\n\\ncolumn_str = [\\\"timestamp\\\", \\\"weekday\\\"]\\nnoise_probability = 0.005\\n\\nkst, pipeline_approved = test_feature_determination(\\n    data, column_str, noise_probability, box=1\\n)\\n\\nX = pipeline_approved[\\\"columntransformer\\\"].transform(data[column_str])\\n\\nprint(\\n    \\\"Transformed columns: \\\",\\n    \\\"\\\\n\\\",\\n    X[1:5, :],\\n    \\\"\\\\n\\\",\\n    \\\"Sample Scores: \\\",\\n    \\\"\\\\n\\\",\\n    kst.score_samples(X[1:5, :]),\\n)\";\n",
       "                var nbb_formatted_code = \"data = pd.read_csv(\\n    \\\"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\\\",\\n    usecols=[\\\"timestamp\\\", \\\"application_uid\\\", \\\"auth_status\\\", \\\"fingerprinttimezone\\\"],\\n)\\n\\ndata[\\\"timestamp\\\"] = data[\\\"timestamp\\\"].apply(lambda x: dt.fromtimestamp(x))\\ndata[\\\"weekday\\\"] = data[\\\"timestamp\\\"].apply(lambda x: \\\"day\\\" + str(x.weekday()))\\n\\n\\ncolumn_str = [\\\"timestamp\\\", \\\"weekday\\\"]\\nnoise_probability = 0.005\\n\\nkst, pipeline_approved = test_feature_determination(\\n    data, column_str, noise_probability, box=1\\n)\\n\\nX = pipeline_approved[\\\"columntransformer\\\"].transform(data[column_str])\\n\\nprint(\\n    \\\"Transformed columns: \\\",\\n    \\\"\\\\n\\\",\\n    X[1:5, :],\\n    \\\"\\\\n\\\",\\n    \\\"Sample Scores: \\\",\\n    \\\"\\\\n\\\",\\n    kst.score_samples(X[1:5, :]),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    \"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\",\n",
    "    usecols=[\"timestamp\", \"application_uid\", \"auth_status\", \"fingerprinttimezone\"],\n",
    ")\n",
    "\n",
    "data[\"timestamp\"] = data[\"timestamp\"].apply(lambda x: dt.fromtimestamp(x))\n",
    "data[\"weekday\"] = data[\"timestamp\"].apply(lambda x: \"day\" + str(x.weekday()))\n",
    "\n",
    "\n",
    "column_str = [\"timestamp\", \"weekday\"]\n",
    "noise_probability = 0.005\n",
    "\n",
    "kst, pipeline_approved = test_feature_determination(\n",
    "    data, column_str, noise_probability, box=1\n",
    ")\n",
    "\n",
    "X = pipeline_approved[\"columntransformer\"].transform(data[column_str])\n",
    "\n",
    "print(\n",
    "    \"Transformed columns: \",\n",
    "    \"\\n\",\n",
    "    X[1:5, :],\n",
    "    \"\\n\",\n",
    "    \"Sample Scores: \",\n",
    "    \"\\n\",\n",
    "    kst.score_samples(X[1:5, :]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "enclosed-conviction",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:kuberspatiotemporal.spatial:(100, 9494)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6948392557731956"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 243;\n",
       "                var nbb_unformatted_code = \"kst.score_samples(X).mean()\";\n",
       "                var nbb_formatted_code = \"kst.score_samples(X).mean()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kst.score_samples(X).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-strain",
   "metadata": {},
   "source": [
    "## Using weekday + timestamp (order reversed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "advance-anger",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fs.categorical_features ['weekday']\n",
      "fs.numerical_features []\n",
      "fs.time_feature ['timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed columns:  \n",
      " [[0.33833333 1.        ]\n",
      " [0.29694444 1.        ]\n",
      " [0.28333333 1.        ]\n",
      " [0.275      1.        ]] \n",
      " Sample Scores:  \n",
      " [0.55975964 0.5460452  0.54109977 0.53796358]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 159;\n",
       "                var nbb_unformatted_code = \"data = pd.read_csv(\\n    \\\"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\\\",\\n    usecols=[\\\"timestamp\\\", \\\"application_uid\\\", \\\"auth_status\\\", \\\"fingerprinttimezone\\\"],\\n)\\n\\ndata[\\\"timestamp\\\"] = data[\\\"timestamp\\\"].apply(lambda x: dt.fromtimestamp(x))\\ndata[\\\"weekday\\\"] = data[\\\"timestamp\\\"].apply(lambda x: \\\"day\\\" + str(x.weekday()))\\n\\n\\ncolumn_str = [\\\"weekday\\\", \\\"timestamp\\\"]\\nnoise_probability = 0.005\\n\\nkst, pipeline_approved = test_feature_determination(\\n    data, column_str, noise_probability, box=1\\n)\\n\\nX = pipeline_approved[\\\"columntransformer\\\"].transform(data[column_str])\\n\\nprint(\\n    \\\"Transformed columns: \\\",\\n    \\\"\\\\n\\\",\\n    X[1:5, :],\\n    \\\"\\\\n\\\",\\n    \\\"Sample Scores: \\\",\\n    \\\"\\\\n\\\",\\n    kst.score_samples(X[1:5, :]),\\n)\";\n",
       "                var nbb_formatted_code = \"data = pd.read_csv(\\n    \\\"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\\\",\\n    usecols=[\\\"timestamp\\\", \\\"application_uid\\\", \\\"auth_status\\\", \\\"fingerprinttimezone\\\"],\\n)\\n\\ndata[\\\"timestamp\\\"] = data[\\\"timestamp\\\"].apply(lambda x: dt.fromtimestamp(x))\\ndata[\\\"weekday\\\"] = data[\\\"timestamp\\\"].apply(lambda x: \\\"day\\\" + str(x.weekday()))\\n\\n\\ncolumn_str = [\\\"weekday\\\", \\\"timestamp\\\"]\\nnoise_probability = 0.005\\n\\nkst, pipeline_approved = test_feature_determination(\\n    data, column_str, noise_probability, box=1\\n)\\n\\nX = pipeline_approved[\\\"columntransformer\\\"].transform(data[column_str])\\n\\nprint(\\n    \\\"Transformed columns: \\\",\\n    \\\"\\\\n\\\",\\n    X[1:5, :],\\n    \\\"\\\\n\\\",\\n    \\\"Sample Scores: \\\",\\n    \\\"\\\\n\\\",\\n    kst.score_samples(X[1:5, :]),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    \"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\",\n",
    "    usecols=[\"timestamp\", \"application_uid\", \"auth_status\", \"fingerprinttimezone\"],\n",
    ")\n",
    "\n",
    "data[\"timestamp\"] = data[\"timestamp\"].apply(lambda x: dt.fromtimestamp(x))\n",
    "data[\"weekday\"] = data[\"timestamp\"].apply(lambda x: \"day\" + str(x.weekday()))\n",
    "\n",
    "\n",
    "column_str = [\"weekday\", \"timestamp\"]\n",
    "noise_probability = 0.005\n",
    "\n",
    "kst, pipeline_approved = test_feature_determination(\n",
    "    data, column_str, noise_probability, box=1\n",
    ")\n",
    "\n",
    "X = pipeline_approved[\"columntransformer\"].transform(data[column_str])\n",
    "\n",
    "print(\n",
    "    \"Transformed columns: \",\n",
    "    \"\\n\",\n",
    "    X[1:5, :],\n",
    "    \"\\n\",\n",
    "    \"Sample Scores: \",\n",
    "    \"\\n\",\n",
    "    kst.score_samples(X[1:5, :]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-header",
   "metadata": {},
   "source": [
    "## Using Only weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "tough-internet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fs.categorical_features ['weekday']\n",
      "fs.numerical_features []\n",
      "fs.time_feature []\n",
      "Transformed columns:  \n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      " Sample Scores:  \n",
      " [0.93415185 0.93415185 0.93415185 0.93415185]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 139;\n",
       "                var nbb_unformatted_code = \"data = pd.read_csv(\\n    \\\"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\\\",\\n    usecols=[\\\"timestamp\\\", \\\"application_uid\\\", \\\"auth_status\\\", \\\"fingerprinttimezone\\\"],\\n)\\n\\ndata[\\\"timestamp\\\"] = data[\\\"timestamp\\\"].apply(lambda x: dt.fromtimestamp(x))\\ndata[\\\"weekday\\\"] = data[\\\"timestamp\\\"].apply(lambda x: \\\"day\\\" + str(x.weekday()))\\n\\n\\ncolumn_str = [\\\"weekday\\\"]\\nnoise_probability = 0.01\\n\\nkst, pipeline_approved = test_feature_determination(data, column_str, noise_probability)\\n\\nX = pipeline_approved[\\\"columntransformer\\\"].transform(data[column_str])\\n\\nprint(\\n    \\\"Transformed columns: \\\",\\n    \\\"\\\\n\\\",\\n    X[1:5, :],\\n    \\\"\\\\n\\\",\\n    \\\"Sample Scores: \\\",\\n    \\\"\\\\n\\\",\\n    kst.score_samples(X[1:5, :]),\\n)\";\n",
       "                var nbb_formatted_code = \"data = pd.read_csv(\\n    \\\"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\\\",\\n    usecols=[\\\"timestamp\\\", \\\"application_uid\\\", \\\"auth_status\\\", \\\"fingerprinttimezone\\\"],\\n)\\n\\ndata[\\\"timestamp\\\"] = data[\\\"timestamp\\\"].apply(lambda x: dt.fromtimestamp(x))\\ndata[\\\"weekday\\\"] = data[\\\"timestamp\\\"].apply(lambda x: \\\"day\\\" + str(x.weekday()))\\n\\n\\ncolumn_str = [\\\"weekday\\\"]\\nnoise_probability = 0.01\\n\\nkst, pipeline_approved = test_feature_determination(data, column_str, noise_probability)\\n\\nX = pipeline_approved[\\\"columntransformer\\\"].transform(data[column_str])\\n\\nprint(\\n    \\\"Transformed columns: \\\",\\n    \\\"\\\\n\\\",\\n    X[1:5, :],\\n    \\\"\\\\n\\\",\\n    \\\"Sample Scores: \\\",\\n    \\\"\\\\n\\\",\\n    kst.score_samples(X[1:5, :]),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    \"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\",\n",
    "    usecols=[\"timestamp\", \"application_uid\", \"auth_status\", \"fingerprinttimezone\"],\n",
    ")\n",
    "\n",
    "data[\"timestamp\"] = data[\"timestamp\"].apply(lambda x: dt.fromtimestamp(x))\n",
    "data[\"weekday\"] = data[\"timestamp\"].apply(lambda x: \"day\" + str(x.weekday()))\n",
    "\n",
    "\n",
    "column_str = [\"weekday\"]\n",
    "noise_probability = 0.01\n",
    "\n",
    "kst, pipeline_approved = test_feature_determination(data, column_str, noise_probability)\n",
    "\n",
    "X = pipeline_approved[\"columntransformer\"].transform(data[column_str])\n",
    "\n",
    "print(\n",
    "    \"Transformed columns: \",\n",
    "    \"\\n\",\n",
    "    X[1:5, :],\n",
    "    \"\\n\",\n",
    "    \"Sample Scores: \",\n",
    "    \"\\n\",\n",
    "    kst.score_samples(X[1:5, :]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-vector",
   "metadata": {},
   "source": [
    "## Use timestamp + 2-D numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "roman-lover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 220;\n",
       "                var nbb_unformatted_code = \"%load_ext autoreload\\n%autoreload 2\";\n",
       "                var nbb_formatted_code = \"%load_ext autoreload\\n%autoreload 2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "aging-coordinator",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fs.categorical_features []\n",
      "fs.numerical_features ['longitude' 'latitude']\n",
      "fs.time_feature ['timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 300)\n",
      "DEBUG:kuberspatiotemporal.spatial:(100, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed columns:  \n",
      " [[  0.33833333 -97.822       37.751     ]\n",
      " [  0.29694444 -97.822       37.751     ]\n",
      " [  0.28333333 -97.822       37.751     ]\n",
      " [  0.275      -97.822       37.751     ]] \n",
      " Sample Scores:  \n",
      " [0.67103624 0.65139676 0.64454623 0.64025488]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 221;\n",
       "                var nbb_unformatted_code = \"data = pd.read_csv(\\\"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\\\",)\\ndata.head()\\n\\n\\ndata[\\\"timestamp\\\"] = data[\\\"timestamp\\\"].apply(lambda x: dt.fromtimestamp(x))\\ndata[\\\"weekday\\\"] = data[\\\"timestamp\\\"].apply(lambda x: \\\"day\\\" + str(x.weekday()))\\n\\ndata = data[~data[\\\"longitude\\\"].isna()]\\n\\ncolumn_str = [\\\"timestamp\\\", \\\"latitude\\\", \\\"longitude\\\"]\\nnoise_probability = 0.01\\n\\nkst, pipeline_approved = test_feature_determination(data, column_str, noise_probability, box = 1)\\n\\nX = pipeline_approved[\\\"columntransformer\\\"].transform(data[column_str])\\n\\nprint(\\n    \\\"Transformed columns: \\\",\\n    \\\"\\\\n\\\",\\n    X[1:5, :],\\n    \\\"\\\\n\\\",\\n    \\\"Sample Scores: \\\",\\n    \\\"\\\\n\\\",\\n    kst.score_samples(X[1:5, :]),\\n)\";\n",
       "                var nbb_formatted_code = \"data = pd.read_csv(\\\"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\\\",)\\ndata.head()\\n\\n\\ndata[\\\"timestamp\\\"] = data[\\\"timestamp\\\"].apply(lambda x: dt.fromtimestamp(x))\\ndata[\\\"weekday\\\"] = data[\\\"timestamp\\\"].apply(lambda x: \\\"day\\\" + str(x.weekday()))\\n\\ndata = data[~data[\\\"longitude\\\"].isna()]\\n\\ncolumn_str = [\\\"timestamp\\\", \\\"latitude\\\", \\\"longitude\\\"]\\nnoise_probability = 0.01\\n\\nkst, pipeline_approved = test_feature_determination(\\n    data, column_str, noise_probability, box=1\\n)\\n\\nX = pipeline_approved[\\\"columntransformer\\\"].transform(data[column_str])\\n\\nprint(\\n    \\\"Transformed columns: \\\",\\n    \\\"\\\\n\\\",\\n    X[1:5, :],\\n    \\\"\\\\n\\\",\\n    \\\"Sample Scores: \\\",\\n    \\\"\\\\n\\\",\\n    kst.score_samples(X[1:5, :]),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\",)\n",
    "data.head()\n",
    "\n",
    "\n",
    "data[\"timestamp\"] = data[\"timestamp\"].apply(lambda x: dt.fromtimestamp(x))\n",
    "data[\"weekday\"] = data[\"timestamp\"].apply(lambda x: \"day\" + str(x.weekday()))\n",
    "\n",
    "data = data[~data[\"longitude\"].isna()]\n",
    "\n",
    "column_str = [\"timestamp\", \"latitude\", \"longitude\"]\n",
    "noise_probability = 0.01\n",
    "\n",
    "kst, pipeline_approved = test_feature_determination(\n",
    "    data, column_str, noise_probability, box=1\n",
    ")\n",
    "\n",
    "X = pipeline_approved[\"columntransformer\"].transform(data[column_str])\n",
    "\n",
    "print(\n",
    "    \"Transformed columns: \",\n",
    "    \"\\n\",\n",
    "    X[1:5, :],\n",
    "    \"\\n\",\n",
    "    \"Sample Scores: \",\n",
    "    \"\\n\",\n",
    "    kst.score_samples(X[1:5, :]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "focused-expansion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.026667</td>\n",
       "      <td>-72.5621</td>\n",
       "      <td>42.0825</td>\n",
       "      <td>0.246008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>23.300278</td>\n",
       "      <td>-72.5621</td>\n",
       "      <td>42.0825</td>\n",
       "      <td>0.434506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>23.283333</td>\n",
       "      <td>-72.5621</td>\n",
       "      <td>42.0825</td>\n",
       "      <td>0.436223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>23.176667</td>\n",
       "      <td>-72.5596</td>\n",
       "      <td>41.8363</td>\n",
       "      <td>0.209766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>22.463056</td>\n",
       "      <td>-72.6420</td>\n",
       "      <td>41.9900</td>\n",
       "      <td>0.216921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9381</th>\n",
       "      <td>15.812222</td>\n",
       "      <td>-71.1349</td>\n",
       "      <td>42.3907</td>\n",
       "      <td>0.232927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9395</th>\n",
       "      <td>15.652222</td>\n",
       "      <td>-72.3196</td>\n",
       "      <td>42.1010</td>\n",
       "      <td>0.424604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9440</th>\n",
       "      <td>14.950833</td>\n",
       "      <td>-72.4070</td>\n",
       "      <td>42.2735</td>\n",
       "      <td>0.239451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9452</th>\n",
       "      <td>14.278333</td>\n",
       "      <td>-71.7719</td>\n",
       "      <td>42.2555</td>\n",
       "      <td>0.288759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9487</th>\n",
       "      <td>2.801111</td>\n",
       "      <td>-72.4721</td>\n",
       "      <td>42.1719</td>\n",
       "      <td>0.354063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>644 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp      lat     long     score\n",
       "10     0.026667 -72.5621  42.0825  0.246008\n",
       "42    23.300278 -72.5621  42.0825  0.434506\n",
       "44    23.283333 -72.5621  42.0825  0.436223\n",
       "50    23.176667 -72.5596  41.8363  0.209766\n",
       "70    22.463056 -72.6420  41.9900  0.216921\n",
       "...         ...      ...      ...       ...\n",
       "9381  15.812222 -71.1349  42.3907  0.232927\n",
       "9395  15.652222 -72.3196  42.1010  0.424604\n",
       "9440  14.950833 -72.4070  42.2735  0.239451\n",
       "9452  14.278333 -71.7719  42.2555  0.288759\n",
       "9487   2.801111 -72.4721  42.1719  0.354063\n",
       "\n",
       "[644 rows x 4 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 192;\n",
       "                var nbb_unformatted_code = \"res = pd.DataFrame(X, columns=[\\\"timestamp\\\", \\\"lat\\\", \\\"long\\\"])\\nres[\\\"score\\\"] = kst.score_samples(X)\\nres[(res[\\\"score\\\"] < 0.5) & (res[\\\"score\\\"] > 0.2)]\";\n",
       "                var nbb_formatted_code = \"res = pd.DataFrame(X, columns=[\\\"timestamp\\\", \\\"lat\\\", \\\"long\\\"])\\nres[\\\"score\\\"] = kst.score_samples(X)\\nres[(res[\\\"score\\\"] < 0.5) & (res[\\\"score\\\"] > 0.2)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = pd.DataFrame(X, columns=[\"timestamp\", \"lat\", \"long\"])\n",
    "res[\"score\"] = kst.score_samples(X)\n",
    "res[(res[\"score\"] < 0.5) & (res[\"score\"] > 0.2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-excitement",
   "metadata": {},
   "source": [
    "## Use only 2-D Numerical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "provincial-powder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fs.categorical_features []\n",
      "fs.numerical_features ['longitude' 'latitude']\n",
      "fs.time_feature []\n",
      "Transformed columns:  \n",
      " [[-97.822  37.751]\n",
      " [-97.822  37.751]\n",
      " [-97.822  37.751]\n",
      " [-97.822  37.751]] \n",
      " Sample Scores:  \n",
      " [0.99999892 0.99999892 0.99999892 0.99999892]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 245;\n",
       "                var nbb_unformatted_code = \"data = pd.read_csv(\\\"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\\\",)\\ndata.head()\\n\\n\\ndata[\\\"timestamp\\\"] = data[\\\"timestamp\\\"].apply(lambda x: dt.fromtimestamp(x))\\ndata[\\\"weekday\\\"] = data[\\\"timestamp\\\"].apply(lambda x: \\\"day\\\" + str(x.weekday()))\\n\\ndata = data[~data[\\\"longitude\\\"].isna()]\\n\\ncolumn_str = [\\\"latitude\\\", \\\"longitude\\\"]\\nnoise_probability = 0.1\\n\\nkst, pipeline_approved = test_feature_determination(\\n    data, column_str, noise_probability\\n)\\n\\nX = pipeline_approved[\\\"columntransformer\\\"].transform(data[column_str])\\n\\nprint(\\n    \\\"Transformed columns: \\\",\\n    \\\"\\\\n\\\",\\n    X[1:5, :],\\n    \\\"\\\\n\\\",\\n    \\\"Sample Scores: \\\",\\n    \\\"\\\\n\\\",\\n    kst.score_samples(X[1:5, :]),\\n)\";\n",
       "                var nbb_formatted_code = \"data = pd.read_csv(\\\"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\\\",)\\ndata.head()\\n\\n\\ndata[\\\"timestamp\\\"] = data[\\\"timestamp\\\"].apply(lambda x: dt.fromtimestamp(x))\\ndata[\\\"weekday\\\"] = data[\\\"timestamp\\\"].apply(lambda x: \\\"day\\\" + str(x.weekday()))\\n\\ndata = data[~data[\\\"longitude\\\"].isna()]\\n\\ncolumn_str = [\\\"latitude\\\", \\\"longitude\\\"]\\nnoise_probability = 0.1\\n\\nkst, pipeline_approved = test_feature_determination(data, column_str, noise_probability)\\n\\nX = pipeline_approved[\\\"columntransformer\\\"].transform(data[column_str])\\n\\nprint(\\n    \\\"Transformed columns: \\\",\\n    \\\"\\\\n\\\",\\n    X[1:5, :],\\n    \\\"\\\\n\\\",\\n    \\\"Sample Scores: \\\",\\n    \\\"\\\\n\\\",\\n    kst.score_samples(X[1:5, :]),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\",)\n",
    "data.head()\n",
    "\n",
    "\n",
    "data[\"timestamp\"] = data[\"timestamp\"].apply(lambda x: dt.fromtimestamp(x))\n",
    "data[\"weekday\"] = data[\"timestamp\"].apply(lambda x: \"day\" + str(x.weekday()))\n",
    "\n",
    "data = data[~data[\"longitude\"].isna()]\n",
    "\n",
    "column_str = [\"latitude\", \"longitude\"]\n",
    "noise_probability = 0.1\n",
    "\n",
    "kst, pipeline_approved = test_feature_determination(data, column_str, noise_probability)\n",
    "\n",
    "X = pipeline_approved[\"columntransformer\"].transform(data[column_str])\n",
    "\n",
    "print(\n",
    "    \"Transformed columns: \",\n",
    "    \"\\n\",\n",
    "    X[1:5, :],\n",
    "    \"\\n\",\n",
    "    \"Sample Scores: \",\n",
    "    \"\\n\",\n",
    "    kst.score_samples(X[1:5, :]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-matter",
   "metadata": {},
   "source": [
    "## Use All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "earned-investigator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fs.categorical_features ['weekday']\n",
      "fs.numerical_features ['longitude' 'latitude']\n",
      "fs.time_feature ['timestamp']\n",
      "Transformed columns:  \n",
      " [[  0.33833333 -97.822       37.751        1.        ]\n",
      " [  0.29694444 -97.822       37.751        1.        ]\n",
      " [  0.28333333 -97.822       37.751        1.        ]\n",
      " [  0.275      -97.822       37.751        1.        ]] \n",
      " Sample Scores:  \n",
      " [0.99999332 0.99999271 0.99999249 0.99999235]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 246;\n",
       "                var nbb_unformatted_code = \"data = pd.read_csv(\\\"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\\\",)\\ndata.head()\\n\\n\\ndata[\\\"timestamp\\\"] = data[\\\"timestamp\\\"].apply(lambda x: dt.fromtimestamp(x))\\ndata[\\\"weekday\\\"] = data[\\\"timestamp\\\"].apply(lambda x: \\\"day\\\" + str(x.weekday()))\\n\\ndata = data[~data[\\\"longitude\\\"].isna()]\\n\\ncolumn_str = [\\\"timestamp\\\", \\\"weekday\\\", \\\"latitude\\\", \\\"longitude\\\"]\\nnoise_probability = 0.005\\n\\nkst, pipeline_approved = test_feature_determination(data, column_str, noise_probability)\\n\\nX = pipeline_approved[\\\"columntransformer\\\"].transform(data[column_str])\\n\\nprint(\\n    \\\"Transformed columns: \\\",\\n    \\\"\\\\n\\\",\\n    X[1:5, :],\\n    \\\"\\\\n\\\",\\n    \\\"Sample Scores: \\\",\\n    \\\"\\\\n\\\",\\n    kst.score_samples(X[1:5, :]),\\n)\";\n",
       "                var nbb_formatted_code = \"data = pd.read_csv(\\\"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\\\",)\\ndata.head()\\n\\n\\ndata[\\\"timestamp\\\"] = data[\\\"timestamp\\\"].apply(lambda x: dt.fromtimestamp(x))\\ndata[\\\"weekday\\\"] = data[\\\"timestamp\\\"].apply(lambda x: \\\"day\\\" + str(x.weekday()))\\n\\ndata = data[~data[\\\"longitude\\\"].isna()]\\n\\ncolumn_str = [\\\"timestamp\\\", \\\"weekday\\\", \\\"latitude\\\", \\\"longitude\\\"]\\nnoise_probability = 0.005\\n\\nkst, pipeline_approved = test_feature_determination(data, column_str, noise_probability)\\n\\nX = pipeline_approved[\\\"columntransformer\\\"].transform(data[column_str])\\n\\nprint(\\n    \\\"Transformed columns: \\\",\\n    \\\"\\\\n\\\",\\n    X[1:5, :],\\n    \\\"\\\\n\\\",\\n    \\\"Sample Scores: \\\",\\n    \\\"\\\\n\\\",\\n    kst.score_samples(X[1:5, :]),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/1fefac90-9903-41fe-94bb-0ed9d9abeae1.csv\",)\n",
    "data.head()\n",
    "\n",
    "\n",
    "data[\"timestamp\"] = data[\"timestamp\"].apply(lambda x: dt.fromtimestamp(x))\n",
    "data[\"weekday\"] = data[\"timestamp\"].apply(lambda x: \"day\" + str(x.weekday()))\n",
    "\n",
    "data = data[~data[\"longitude\"].isna()]\n",
    "\n",
    "column_str = [\"timestamp\", \"weekday\", \"latitude\", \"longitude\"]\n",
    "noise_probability = 0.005\n",
    "\n",
    "kst, pipeline_approved = test_feature_determination(data, column_str, noise_probability)\n",
    "\n",
    "X = pipeline_approved[\"columntransformer\"].transform(data[column_str])\n",
    "\n",
    "print(\n",
    "    \"Transformed columns: \",\n",
    "    \"\\n\",\n",
    "    X[1:5, :],\n",
    "    \"\\n\",\n",
    "    \"Sample Scores: \",\n",
    "    \"\\n\",\n",
    "    kst.score_samples(X[1:5, :]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "adjusted-devices",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>weekday</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.026667</td>\n",
       "      <td>-72.5621</td>\n",
       "      <td>42.0825</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.235270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>19.681389</td>\n",
       "      <td>-72.5508</td>\n",
       "      <td>42.1139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>19.469722</td>\n",
       "      <td>-72.5621</td>\n",
       "      <td>42.0825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>19.450278</td>\n",
       "      <td>-72.5621</td>\n",
       "      <td>42.0825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.231588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>19.396944</td>\n",
       "      <td>-72.7522</td>\n",
       "      <td>42.1293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.211653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9437</th>\n",
       "      <td>15.015833</td>\n",
       "      <td>-72.5771</td>\n",
       "      <td>42.1763</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.338682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9440</th>\n",
       "      <td>14.950833</td>\n",
       "      <td>-72.4070</td>\n",
       "      <td>42.2735</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.288321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9442</th>\n",
       "      <td>14.876944</td>\n",
       "      <td>-72.4721</td>\n",
       "      <td>42.1719</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.338039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9451</th>\n",
       "      <td>14.455556</td>\n",
       "      <td>-72.4464</td>\n",
       "      <td>42.1245</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.303188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9487</th>\n",
       "      <td>2.801111</td>\n",
       "      <td>-72.4721</td>\n",
       "      <td>42.1719</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.389242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1193 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp  latitude  longitude  weekday     score\n",
       "10     0.026667  -72.5621    42.0825      1.0  0.235270\n",
       "225   19.681389  -72.5508    42.1139      0.0  0.200593\n",
       "232   19.469722  -72.5621    42.0825      0.0  0.229757\n",
       "234   19.450278  -72.5621    42.0825      0.0  0.231588\n",
       "239   19.396944  -72.7522    42.1293      0.0  0.211653\n",
       "...         ...       ...        ...      ...       ...\n",
       "9437  15.015833  -72.5771    42.1763      4.0  0.338682\n",
       "9440  14.950833  -72.4070    42.2735      4.0  0.288321\n",
       "9442  14.876944  -72.4721    42.1719      4.0  0.338039\n",
       "9451  14.455556  -72.4464    42.1245      4.0  0.303188\n",
       "9487   2.801111  -72.4721    42.1719      4.0  0.389242\n",
       "\n",
       "[1193 rows x 5 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 198;\n",
       "                var nbb_unformatted_code = \"res = pd.DataFrame(X, columns=[\\\"timestamp\\\",  \\\"latitude\\\", \\\"longitude\\\",\\\"weekday\\\"])\\nres[\\\"score\\\"] = kst.score_samples(X)\\nres[(res[\\\"score\\\"] < 0.5) & (res[\\\"score\\\"] > 0.2)]\";\n",
       "                var nbb_formatted_code = \"res = pd.DataFrame(X, columns=[\\\"timestamp\\\", \\\"latitude\\\", \\\"longitude\\\", \\\"weekday\\\"])\\nres[\\\"score\\\"] = kst.score_samples(X)\\nres[(res[\\\"score\\\"] < 0.5) & (res[\\\"score\\\"] > 0.2)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = pd.DataFrame(X, columns=[\"timestamp\", \"latitude\", \"longitude\", \"weekday\"])\n",
    "res[\"score\"] = kst.score_samples(X)\n",
    "res[(res[\"score\"] < 0.5) & (res[\"score\"] > 0.2)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
